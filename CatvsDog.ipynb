{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CatvsDog.ipynb",
      "provenance": [],
      "mount_file_id": "1G1C-_b4HqDlV4YOVt1vWqEXChXjXb9Mo",
      "authorship_tag": "ABX9TyM3LkKI1BvTPTIw06vZ17qB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WeiHongWi/CatvsDog/blob/main/CatvsDog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyldRvHCW3pD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive\")\n",
        "!ls"
      ],
      "metadata": {
        "id": "qQX2tBhte4AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "mQYh7WckfN_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd examples/imagenet"
      ],
      "metadata": {
        "id": "O3qF8YMOiOlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41acd148-f6b8-4688-e448-c1f821bf3697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'examples/imagenet'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "-Bwm6wH1kTYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "from torch.optim import Adam\n",
        "from torchvision import datasets ,models,transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn import Linear, CrossEntropyLoss, Module\n",
        "\n",
        "\n",
        "path_train = r'/content/drive/MyDrive/examples/imagenet/train'\n",
        "TRAIN =Path(path_train)\n",
        "\n",
        "#將數據集的圖片一律改成224*224，並丟入function transform成 size:224*224,tensor,\n",
        "#Tensor()將images的每個pixels轉成-1.0~1.0之間的數值\n",
        "transforms = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n"
      ],
      "metadata": {
        "id": "T7FqGg4JwWmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#將train set分類\n",
        "train_data = datasets.ImageFolder(TRAIN, transform=transforms)\n",
        "print(train_data.class_to_idx)\n",
        "\n",
        "#將train分成80%train set和20%validation set\n",
        "print(len(train_data))\n",
        "train_size = int(0.8 * len(train_data))\n",
        "valid_size = int(0.2 * len(train_data))\n",
        "print(train_size)\n",
        "\n",
        "#根據size大小運用函數來隨機分配給數據集\n",
        "train_data , valid_data = torch.utils.data.random_split(train_data,[train_size,valid_size])\n",
        "\n",
        "#將Dataset裏頭的data先打亂在分配成batch\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100,shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=100,shuffle=True)\n",
        "\n",
        "for i,item in enumerate(valid_loader):\n",
        "  l = item\n",
        "  print('data:',data)\n",
        "  print('label:',label)\n"
      ],
      "metadata": {
        "id": "L59TKav-Be9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "#構建 resnet18\n",
        "from torchvision.models.resnet import resnet18\n",
        "resnet = resnet18()\n",
        "\n",
        "#從print的最後一層輸出的維度為1000，但我們需要的只有貓跟狗，所以只用2種就好，修改resnet\n",
        "fc_feature = resnet.fc.in_features\n",
        "resnet.fc = Linear(fc_feature,2)\n",
        "\n",
        "#print(resnet.fc)\n",
        "#print(resnet)\n"
      ],
      "metadata": {
        "id": "-U2ZfyjUQTo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#設定訓練參數\n",
        "lr = 0.01\n",
        "epochs = 15\n",
        "input_size = 224\n",
        "batch_size = 100"
      ],
      "metadata": {
        "id": "uZVqq7kkam_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#用GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = resnet.to(device) #將resnet丟進GPU\n",
        "#Train\n",
        "def train(net,optimizer,device,criterion,train_loader,epoch):\n",
        "\n",
        "  net.train()\n",
        "  batch_number = len(train_loader)\n",
        "  run_loss = 0.0\n",
        "  correct = 0\n",
        "  traintime = 0.0\n",
        "\n",
        "  for i,data in enumerate(train_loader,start = 1):\n",
        "    start = time.time()\n",
        "    #將input的資料要送入GPU\n",
        "    inputs ,labels = data\n",
        "    inputs ,labels = inputs.to(device) , labels.to(device)\n",
        "    \n",
        "    outputs = net(inputs) #順向傳遞\n",
        "    \n",
        "    loss = criterion(outputs,labels) #計算loss\n",
        "    \n",
        "    optimizer.zero_grad()#若沒有這個function，則梯度自動累加\n",
        "    loss.backward()#反向傳遞\n",
        "    optimizer.step()#更新所有參數\n",
        "    \n",
        "    transpre = outputs.data.max(dim=1)[1]\n",
        "    total = outputs.shape[0]\n",
        "    correct += (transpre == labels).sum().item()\n",
        "    run_loss += loss.item()\n",
        "    end = time.time()\n",
        "    e = end-start\n",
        "    traintime = traintime + e\n",
        "    #print(traintime)\n",
        "    #print(total)\n",
        "    \n",
        "    \n",
        "    if i%10 == 0:\n",
        "      #print(correct)\n",
        "      total = total*10\n",
        "      acc = 100*correct/total\n",
        "      print('Epoch:[{}][{}/{}] Time:{} loss:{:3f} Acc:{} '.format(epoch+1,i,batch_number,traintime,run_loss/10,acc))\n",
        "      run_loss = 0.0\n",
        "      correct = 0\n",
        "      traintime = 0\n",
        "#Validation\n",
        "def valid(net,device,valid_loader,criterion):\n",
        "  net.eval() #關閉dropout，訓練好的網路才不會改變\n",
        "  batch_number = len(valid_loader)\n",
        "  val_run_loss = 0.0\n",
        "  vcorrect = 0\n",
        "  val_total = 0\n",
        "  testtime = 0\n",
        "  for i,target in enumerate(valid_loader,start = 1):\n",
        "    with torch.no_grad(): #停止gradient計算，加速計算\n",
        "      start = time.time()\n",
        "      images,labels = target\n",
        "      images,labels = images.to(device),labels.to(device)\n",
        "      \n",
        "      valid_outputs = net(images)\n",
        "      validpre = valid_outputs.data.max(dim=1)[1]\n",
        "\n",
        "      vcorrect +=(validpre == labels).sum().item()\n",
        "      val_run_loss += criterion(valid_outputs,labels).item()\n",
        "      val_total += valid_outputs.shape[0]\n",
        "      \n",
        "      end = time.time()\n",
        "      e = end-start\n",
        "      testtime = testtime + e\n",
        "      \n",
        "      if i%10 == 0:\n",
        "        #print(vcorrect)\n",
        "        accv = 100*vcorrect/val_total\n",
        "        print('Test:[{}/{}] Time:{} loss:{:.6f} Acc:{} '.format(i,batch_number,testtime,val_run_loss/10,accv))\n",
        "        val_run_loss = 0.0\n",
        "        vcorrect = 0\n",
        "        testtime = 0\n",
        "        val_total = 0\n",
        "\n",
        "#開始訓練\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.fc.parameters(),lr=lr)\n",
        "for epoch in range(epochs):\n",
        "  print('{}th Train'.format(epoch+1))\n",
        "  train(net,optimizer,device,criterion,train_loader,epoch)\n",
        "  valid(net,device,valid_loader,criterion)"
      ],
      "metadata": {
        "id": "d7ffZ8HJcLzu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}